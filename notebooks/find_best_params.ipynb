{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64d4b225",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02c32090",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/02 13:37:58 WARN Utils: spark.executor.instances less than spark.dynamicAllocation.minExecutors is invalid, ignoring its setting, please update your configs.\n",
      "25/05/02 13:37:59 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
      "25/05/02 13:38:15 WARN Utils: spark.executor.instances less than spark.dynamicAllocation.minExecutors is invalid, ignoring its setting, please update your configs.\n"
     ]
    }
   ],
   "source": [
    "# ====================== INITIALISATION ======================\n",
    "# VÃ©rifiez si un SparkContext existe dÃ©jÃ \n",
    "if 'sc' in locals() or 'sc' in globals():\n",
    "    sc.stop()  # ArrÃªtez le SparkContext prÃ©cÃ©dent\n",
    "    \n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TrainALSModel\") \\\n",
    "    .master(\"yarn\") \\\n",
    "    .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acbe9a61",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Lecture des fichiers CSV depuis HDFS...\n"
     ]
    }
   ],
   "source": [
    "# ====================== CHARGEMENT DES DONNÃ‰ES ======================\n",
    "ratings_schema = StructType([\n",
    "    StructField(\"userId\", IntegerType(), True),\n",
    "    StructField(\"movieId\", IntegerType(), True),\n",
    "    StructField(\"rating\", FloatType(), True),\n",
    "    StructField(\"timestamp\", StringType(), True),\n",
    "])\n",
    "\n",
    "movies_schema = StructType([\n",
    "    StructField(\"movieId\", IntegerType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"genres\", StringType(), True),\n",
    "])\n",
    "\n",
    "print(\"ðŸ“¥ Lecture des fichiers CSV depuis HDFS...\")\n",
    "ratings_df = spark.read.csv(\"hdfs:///input/rating.csv\", header=True, schema=ratings_schema)\n",
    "movies_df = spark.read.csv(\"hdfs:///input/movie.csv\", header=True, schema=movies_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62bbce19",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ====================== NETTOYAGE ======================\n",
    "# Supprimer les lignes avec valeurs nulles\n",
    "ratings_df = ratings_df.dropna(subset=[\"userId\", \"movieId\", \"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1940497a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ====================== DIVISION TRAIN / TEST ======================\n",
    "train_df, test_df = ratings_df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "242e2e00",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒŸ Meilleurs paramÃ¨tres :\n",
      "- Rank (facteurs latents) : 16\n",
      "- ItÃ©rations max : 20\n",
      "- RÃ©gularisation (regParam) : 0.05\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'evaluator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# PrÃ©dictions sur le test set avec le meilleur modÃ¨le\u001b[39;00m\n\u001b[1;32m     41\u001b[0m best_predictions \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mtransform(test_df)\n\u001b[0;32m---> 42\u001b[0m final_rmse \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate(best_predictions)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸš€ RMSE aprÃ¨s optimisation : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_rmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluator' is not defined"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# ====================== DÃ‰FINIR ALS ======================\n",
    "als = ALS(\n",
    "    userCol=\"userId\",\n",
    "    itemCol=\"movieId\",\n",
    "    ratingCol=\"rating\",\n",
    "    nonnegative=True,\n",
    "    coldStartStrategy=\"drop\",\n",
    "    implicitPrefs=False  # Ã€ ajuster si vous utilisez des donnÃ©es implicites\n",
    ")\n",
    "\n",
    "# ====================== GRID SEARCH ======================\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(als.rank, [8, 12, 16]) \\\n",
    "    .addGrid(als.maxIter, [10, 15, 20]) \\\n",
    "    .addGrid(als.regParam, [0.01, 0.05, 0.1]) \\\n",
    "    .build()\n",
    "\n",
    "# ====================== VALIDATION CROISÃ‰E ======================\n",
    "crossval = CrossValidator(\n",
    "    estimator=als,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\"),\n",
    "    numFolds=3,\n",
    "    parallelism=4\n",
    ")\n",
    "\n",
    "# Lancer l'optimisation\n",
    "cv_model = crossval.fit(train_df)\n",
    "\n",
    "# RÃ©cupÃ©rer le meilleur modÃ¨le\n",
    "best_model = cv_model.bestModel\n",
    "\n",
    "print(f\"ðŸŒŸ Meilleurs paramÃ¨tres :\")\n",
    "print(f\"- Rank (facteurs latents) : {best_model.rank}\")\n",
    "print(f\"- ItÃ©rations max : {best_model._java_obj.parent().getMaxIter()}\")\n",
    "print(f\"- RÃ©gularisation (regParam) : {best_model._java_obj.parent().getRegParam()}\")\n",
    "\n",
    "# PrÃ©dictions sur le test set avec le meilleur modÃ¨le\n",
    "best_predictions = best_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2ffac2f-9bdb-4e04-adbe-16430a7ff29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12832:==================>                                    (1 + 2) / 3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ RMSE aprÃ¨s optimisation : 0.7847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# PrÃ©dictions sur le test set avec le meilleur modÃ¨le\n",
    "best_predictions = best_model.transform(test_df)\n",
    "\n",
    "# DÃ©finir l'Ã©valuateur RMSE\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "\n",
    "# Ã‰valuer le RMSE final\n",
    "final_rmse = evaluator.evaluate(best_predictions)\n",
    "print(f\"ðŸš€ RMSE aprÃ¨s optimisation : {final_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e15fb1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "    # # ====================== Ã‰VALUATION ======================\n",
    "    # print(\"ðŸ“Š Ã‰valuation du modÃ¨le...\")\n",
    "    # predictions = model.transform(test_df)\n",
    "\n",
    "    # evaluator = RegressionEvaluator(\n",
    "    #     metricName=\"rmse\",\n",
    "    #     labelCol=\"rating\",\n",
    "    #     predictionCol=\"prediction\"\n",
    "    # )\n",
    "    # rmse = evaluator.evaluate(predictions)\n",
    "    # print(f\"âœ… RMSE sur l'ensemble test : {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f840c1e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# # ====================== ENREGISTREMENT ======================\n",
    "# print(\"ðŸ’¾ Sauvegarde du modÃ¨le dans HDFS (/models/als)...\")\n",
    "# model.write().overwrite().save(\"hdfs:///models/als\")\n",
    "\n",
    "# print(\"ðŸŽ‰ ModÃ¨le entraÃ®nÃ© et sauvegardÃ© avec succÃ¨s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcabd3e6-67b8-40e7-9191-dac5cfc522d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
