{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8607c89f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functions \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m count\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql.functions import count\n",
    "import numpy as np\n",
    "from pyspark.sql.window import Window\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e5dcb3-cfb4-45e9-b88d-6dbd7a354553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifiez si un SparkContext existe d√©j√†\n",
    "if 'sc' in locals() or 'sc' in globals():\n",
    "    sc.stop()  # Arr√™tez le SparkContext pr√©c√©dent\n",
    "    \n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ExploreRatingCSV\") \\\n",
    "    .master(\"yarn\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ed0ed5-bfdd-4929-83c4-6471010404ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "ratings_df = spark.read.csv(\"hdfs:///input/rating.csv\", header=True, inferSchema=True)\n",
    "movies_df = spark.read.csv(\"hdfs:///input/movie.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b119b73e",
   "metadata": {},
   "source": [
    "# Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9cfb07-f857-4e03-9de9-9b7d977e2839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les 5 premi√®res lignes de ratings_df\n",
    "print(\"Premi√®res lignes de ratings_df:\")\n",
    "ratings_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a133da-011c-4c02-9242-c701bfa586d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rification des valeurs nulles dans ratings_df\n",
    "print(\"V√©rification des valeurs nulles dans ratings_df :\")\n",
    "ratings_null_counts = ratings_df.select([((F.col(c).isNull()).cast(\"int\")).alias(c) for c in ratings_df.columns]) \\\n",
    "                                .agg(*[F.sum(F.col(c)).alias(c) for c in ratings_df.columns]) \\\n",
    "                                .collect()[0].asDict()\n",
    "for col_name, null_count in ratings_null_counts.items():\n",
    "    print(f\"{col_name}: {null_count} null(s)\")\n",
    "\n",
    "# Afficher les lignes contenant des valeurs nulles dans ratings_df\n",
    "print(\"\\nLignes contenant des valeurs nulles dans ratings_df :\")\n",
    "condition = None\n",
    "for c in ratings_df.columns:\n",
    "    if condition is None:\n",
    "        condition = F.col(c).isNull()\n",
    "    else:\n",
    "        condition = condition | F.col(c).isNull()\n",
    "\n",
    "ratings_df.filter(condition).show(5)\n",
    "\n",
    "# V√©rification des doublons dans ratings_df\n",
    "print(\"\\nV√©rification des doublons dans ratings_df :\")\n",
    "duplicates_count = ratings_df.count() - ratings_df.distinct().count()\n",
    "print(f\"Nombre de doublons : {duplicates_count}\")\n",
    "ratings_df.groupBy(ratings_df.columns).count().filter(\"count > 1\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4641bf90-bae4-42ed-9c49-8ead8e09b87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compter le nombre d'√©valuations par utilisateur\n",
    "user_rating_counts = ratings_df.groupBy(\"userId\").count()\n",
    "\n",
    "# Filtrer pour obtenir les utilisateurs ayant moins de deux √©valuations\n",
    "users_with_less_than_two = user_rating_counts.filter(F.col(\"count\") < 2)\n",
    "\n",
    "# Compter le nombre total d'utilisateurs concern√©s\n",
    "num_users_with_less_than_two = users_with_less_than_two.count()\n",
    "\n",
    "print(f\"Nombre d'utilisateurs ayant moins de deux √©valuations: {num_users_with_less_than_two}\")\n",
    "\n",
    "# Afficher quelques exemples de ces utilisateurs et leur nombre d'√©valuations\n",
    "print(\"\\nExemples d'utilisateurs avec moins de deux √©valuations:\")\n",
    "users_with_less_than_two.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e03a6d5-9e5e-4f7a-b5e1-f33d63366a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compter le nombre de films distincts √©valu√©s par chaque utilisateur\n",
    "distinct_movie_counts = ratings_df.groupBy(\"userId\").agg(\n",
    "    F.countDistinct(\"movieId\").alias(\"distinct_movies_rated\")\n",
    ")\n",
    "\n",
    "# Trier par nombre de films distincts en ordre croissant\n",
    "sorted_users = distinct_movie_counts.orderBy(\"distinct_movies_rated\")\n",
    "\n",
    "# Trouver l'utilisateur avec le moins de films distincts √©valu√©s\n",
    "user_with_least_movies = sorted_users.first()\n",
    "\n",
    "print(f\"L'utilisateur ayant √©valu√© le moins de films distincts est:\")\n",
    "print(f\"userId: {user_with_least_movies['userId']}, avec {user_with_least_movies['distinct_movies_rated']} film(s) √©valu√©(s)\")\n",
    "\n",
    "# Afficher les 5 utilisateurs ayant √©valu√© le moins de films distincts\n",
    "print(\"\\nLes 5 utilisateurs ayant √©valu√© le moins de films distincts:\")\n",
    "sorted_users.show(5)\n",
    "\n",
    "# Pour examiner les √©valuations de cet utilisateur \n",
    "user_id = user_with_least_movies['userId']\n",
    "print(f\"\\nD√©tail des √©valuations de l'utilisateur {user_id}:\")\n",
    "ratings_df.filter(F.col(\"userId\") == user_id).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e5954d-cc51-4e35-abe2-9eacc42cdc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agr√©ger d'abord c√¥t√© Spark (faible volume, typiquement < 20 lignes)\n",
    "agg_df = ratings_df.groupBy(\"rating\").count().orderBy(\"rating\")\n",
    "\n",
    "# Convertir en pandas (ici c‚Äôest s√ªr que √ßa tient en m√©moire)\n",
    "agg_pd = agg_df.toPandas()\n",
    "\n",
    "# Calculer la distribution cumulative\n",
    "agg_pd[\"percentage\"] = agg_pd[\"count\"] / agg_pd[\"count\"].sum()\n",
    "agg_pd[\"cumulative\"] = agg_pd[\"percentage\"].cumsum()\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# üìä Distribution simple\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x=\"rating\", y=\"count\", hue=\"rating\", data=agg_pd, palette=\"viridis\", legend=False)\n",
    "plt.title('Rating Frequency Distribution')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc3ec2c",
   "metadata": {},
   "source": [
    "# Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56902ad-a6ec-477b-bbe7-71e9b16841cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les 5 premi√®res lignes de movies_df\n",
    "print(\"Premi√®res lignes de movies_df:\")\n",
    "movies_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b3b480-b1ac-4157-aafc-a2f8b1152851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rification des valeurs nulles dans movies_df\n",
    "print(\"\\nV√©rification des valeurs nulles dans movies_df :\")\n",
    "movies_null_counts = movies_df.select([((F.col(c).isNull()).cast(\"int\")).alias(c) for c in movies_df.columns]) \\\n",
    "                              .agg(*[F.sum(F.col(c)).alias(c) for c in movies_df.columns]) \\\n",
    "                              .collect()[0].asDict()\n",
    "for col_name, null_count in movies_null_counts.items():\n",
    "    print(f\"{col_name}: {null_count} null(s)\")\n",
    "\n",
    "# Afficher les lignes contenant des valeurs nulles dans movies_df\n",
    "print(\"\\nLignes contenant des valeurs nulles dans movies_df :\")\n",
    "condition = None\n",
    "for c in movies_df.columns:\n",
    "    if condition is None:\n",
    "        condition = F.col(c).isNull()\n",
    "    else:\n",
    "        condition = condition | F.col(c).isNull()\n",
    "\n",
    "movies_df.filter(condition).show(5)\n",
    "\n",
    "# V√©rification des doublons dans movies_df\n",
    "print(\"\\nV√©rification des doublons dans movies_df :\")\n",
    "duplicates_count = movies_df.count() - movies_df.distinct().count()\n",
    "print(f\"Nombre de doublons : {duplicates_count}\")\n",
    "movies_df.groupBy(movies_df.columns).count().filter(\"count > 1\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086049ff-d86b-4263-b1ed-f62a1541da54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activit√© des utilisateurs : nombre de notes par user\n",
    "user_activity_df = ratings_df.groupBy(\"userId\").agg(count(\"*\").alias(\"rating_count\"))\n",
    "user_activity_pd = user_activity_df.toPandas()\n",
    "\n",
    "# Popularit√© des films : nombre de notes par film\n",
    "movie_popularity_df = ratings_df.groupBy(\"movieId\").agg(count(\"*\").alias(\"rating_count\"))\n",
    "movie_popularity_pd = movie_popularity_df.toPandas()\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# üìä Activit√© utilisateurs - avec labels am√©lior√©s et nouvelle couleur\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(np.log10(user_activity_pd[\"rating_count\"]), bins=50, kde=True, color='steelblue')\n",
    "plt.title('Distribution de l\\'activit√© des utilisateurs', fontsize=13, fontweight='bold')\n",
    "plt.xlabel('Log10(Nombre d\\'√©valuations par utilisateur)')\n",
    "plt.ylabel('Nombre d\\'utilisateurs')\n",
    "plt.grid(True, alpha=0.3, linestyle='--')\n",
    "plt.annotate('√âchelle logarithmique', xy=(0.05, 0.95), xycoords='axes fraction', \n",
    "             fontsize=10, bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", alpha=0.8))\n",
    "\n",
    "# üìä Popularit√© des films - avec labels am√©lior√©s et nouvelle couleur\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(np.log10(movie_popularity_pd[\"rating_count\"]), bins=50, kde=True, color='darkorange')\n",
    "plt.title('Distribution de la popularit√© des films', fontsize=13, fontweight='bold')\n",
    "plt.xlabel('Log10(Nombre d\\'√©valuations par film)')\n",
    "plt.ylabel('Nombre de films')\n",
    "plt.grid(True, alpha=0.3, linestyle='--')\n",
    "plt.annotate('√âchelle logarithmique', xy=(0.05, 0.95), xycoords='axes fraction', \n",
    "             fontsize=10, bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Analyse des distributions dans le dataset MovieLens', fontsize=15, y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35c3ba6",
   "metadata": {},
   "source": [
    "Analyse des Distributions du Dataset MovieLens\n",
    "1. Comportement des Utilisateurs\n",
    "Le graphique de gauche r√©v√®le comment les utilisateurs interagissent avec la plateforme:\n",
    "\n",
    "Distribution logarithmique: La visualisation utilise une √©chelle logarithmique (base 10) pour repr√©senter efficacement la large gamme d'activit√©s utilisateur\n",
    "Zone d'activit√© typique: La majorit√© des utilisateurs √©valuent entre 30 et 300 films (10^1.5 √† 10^2.5)\n",
    "Comportement m√©dian: Le pic √† 10^1.5 indique qu'un utilisateur typique √©value environ 30-40 films\n",
    "\"Super-utilisateurs\": La queue de distribution montre une minorit√© d'utilisateurs tr√®s actifs √©valuant jusqu'√† 3000+ films (10^3.5)\n",
    "\n",
    "2. Popularit√© des Films\n",
    "Le graphique de droite montre comment l'attention se distribue parmi les films:\n",
    "\n",
    "Forte in√©galit√©: La courbe r√©v√®le une distribution extr√™mement asym√©trique avec un pic prononc√© pr√®s de 10^0\n",
    "\"Longue tra√Æne\": La grande majorit√© des films re√ßoit tr√®s peu d'√©valuations (entre 1 et 10)\n",
    "Films blockbusters: Un petit nombre de films accumule des milliers d'√©valuations (jusqu'√† 10^4)\n",
    "Loi de puissance: Cette distribution suit typiquement une loi de puissance, caract√©ristique des ph√©nom√®nes de popularit√©\n",
    "\n",
    "3. Implications pour les Syst√®mes de Recommandation\n",
    "Ces distributions ont des cons√©quences importantes pour la conception d'algorithmes efficaces:\n",
    "D√©fis Techniques\n",
    "\n",
    "Matrice creuse: La matrice utilisateurs-films contient principalement des valeurs manquantes, compliquant l'analyse\n",
    "Signal-bruit: Les films peu √©valu√©s offrent un signal statistique faible pour les pr√©dictions\n",
    "D√©s√©quilibre d'information: Les d√©cisions sont souvent biais√©es vers les items populaires et les utilisateurs actifs\n",
    "\n",
    "Strat√©gies de Correction\n",
    "\n",
    "Normalisation des donn√©es: Pond√©rer les √©valuations pour r√©duire l'influence disproportionn√©e des super-utilisateurs\n",
    "R√©gularisation: Appliquer des techniques comme la r√©gularisation L2 dans les mod√®les de factorisation matricielle\n",
    "Diversification forc√©e: Int√©grer des m√©canismes pour promouvoir les contenus de la longue tra√Æne\n",
    "Approches hybrides: Combiner le filtrage collaboratif avec des m√©thodes bas√©es sur le contenu moins sensibles aux biais\n",
    "\n",
    "Opportunit√©s\n",
    "\n",
    "Segmentation d'utilisateurs: Identifier des groupes d'utilisateurs avec diff√©rents niveaux d'engagement\n",
    "D√©couvrabilit√©: Cr√©er des m√©canismes pour aider les utilisateurs √† d√©couvrir des films de niche\n",
    "Personnalisation avanc√©e: Exploiter les donn√©es des super-utilisateurs comme source d'information riche pour am√©liorer les recommandations pour tous\n",
    "\n",
    "Ces distributions asym√©triques sont caract√©ristiques des syst√®mes de recommandation et repr√©sentent √† la fois un d√©fi et une opportunit√© pour d√©velopper des algorithmes plus sophistiqu√©s et √©quitables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bb619e-5b13-484c-832a-39494f817f30",
   "metadata": {},
   "source": [
    "# Ponderation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd13a7c0-66e1-432b-acca-30ecd730543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType, StringType\n",
    "\n",
    "# ====================== INITIALISATION ======================\n",
    "# V√©rifiez si un SparkContext existe d√©j√†\n",
    "if 'sc' in locals() or 'sc' in globals():\n",
    "    sc.stop()  # Arr√™tez le SparkContext pr√©c√©dent\n",
    "    \n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"WeightedRatingWithBias\") \\\n",
    "    .master(\"yarn\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Chemin de sortie pour les donn√©es pond√©r√©es\n",
    "output_path = \"hdfs:///processed/weighted_ratings.csv\"\n",
    "\n",
    "# ====================== CHARGEMENT DES DONN√âES ======================\n",
    "print(\"üì• Chargement des donn√©es...\")\n",
    "\n",
    "# Charger les donn√©es de ratings et films (assurez-vous que les fichiers existent)\n",
    "ratings_df = spark.read.csv(\"hdfs:///input/rating.csv\", header=True, inferSchema=True)\n",
    "movies_df = spark.read.csv(\"hdfs:///input/movie.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# V√©rification du chargement\n",
    "print(f\"‚úÖ Donn√©es de ratings charg√©es: {ratings_df.count()} lignes\")\n",
    "print(f\"‚úÖ Donn√©es de films charg√©es: {movies_df.count()} lignes\")\n",
    "\n",
    "# ====================== CALCUL DES STATISTIQUES UTILISATEUR ET FILM ======================\n",
    "print(\"üßÆ Calcul des statistiques pour la pond√©ration...\")\n",
    "\n",
    "# Calcul des statistiques par utilisateur\n",
    "user_stats = ratings_df.groupBy(\"userId\").agg(\n",
    "    F.count(\"rating\").alias(\"user_count\"),\n",
    "    F.avg(\"rating\").alias(\"user_mean\"),\n",
    "    F.stddev(\"rating\").alias(\"user_stddev\")\n",
    ")\n",
    "\n",
    "# Calcul des statistiques par film\n",
    "movie_stats = ratings_df.groupBy(\"movieId\").agg(\n",
    "    F.count(\"rating\").alias(\"movie_count\"),\n",
    "    F.avg(\"rating\").alias(\"movie_avg_rating\")\n",
    ")\n",
    "\n",
    "# V√©rification des statistiques\n",
    "print(f\"‚úÖ Statistiques utilisateur calcul√©es : {user_stats.count()} utilisateurs\")\n",
    "print(f\"‚úÖ Statistiques film calcul√©es : {movie_stats.count()} films\")\n",
    "\n",
    "# ====================== APPLICATION DE LA PONDERATION ======================\n",
    "print(\"‚öñÔ∏è Application des pond√©rations et ajustements...\")\n",
    "\n",
    "# Joindre les statistiques utilisateur et film avec les donn√©es de ratings\n",
    "weighted_df = ratings_df.join(user_stats, on=\"userId\") \\\n",
    "                        .join(movie_stats, on=\"movieId\") \\\n",
    "                        .join(movies_df, on=\"movieId\")  # Joindre les informations du film\n",
    "\n",
    "print(f\"‚úÖ Donn√©es jointes avec les statistiques: {weighted_df.count()} lignes\")\n",
    "\n",
    "# Calcul des √©valuations normalis√©es et des poids\n",
    "processed_df = weighted_df.withColumn(\n",
    "    # Normalisation Z-score par utilisateur\n",
    "    \"normalized_rating\", \n",
    "    (F.col(\"rating\") - F.col(\"user_mean\")) / \n",
    "    F.when(F.col(\"user_stddev\") > 0, F.col(\"user_stddev\")).otherwise(1.0)\n",
    ").withColumn(\n",
    "    # Poids utilisateur (inversement proportionnel √† l'activit√©)\n",
    "    \"user_weight\", \n",
    "    1.0 / F.log1p(F.col(\"user_count\"))\n",
    ").withColumn(\n",
    "    # Poids film (inversement proportionnel √† la popularit√©)\n",
    "    \"movie_weight\", \n",
    "    1.0 / F.log1p(F.col(\"movie_count\"))\n",
    ").withColumn(\n",
    "    # Confiance combin√©e\n",
    "    \"confidence\", \n",
    "    F.col(\"user_weight\") * F.col(\"movie_weight\")\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Pond√©ration appliqu√©e avec succ√®s\")\n",
    "\n",
    "# ====================== V√âRIFICATION DE LA PONDERATION ======================\n",
    "print(\"\\nüìà Statistiques des pond√©rations :\")\n",
    "processed_df.select(\n",
    "    F.min(\"confidence\").alias(\"min_confidence\"),\n",
    "    F.max(\"confidence\").alias(\"max_confidence\"),\n",
    "    F.avg(\"confidence\").alias(\"avg_confidence\"),\n",
    "    F.min(\"normalized_rating\").alias(\"min_norm_rating\"),\n",
    "    F.max(\"normalized_rating\").alias(\"max_norm_rating\")\n",
    ").show()\n",
    "\n",
    "# ====================== S√âLECTION ET ENREGISTREMENT DES DONN√âES FINAL ======================\n",
    "# S√©lectionner les colonnes importantes pour l'enregistrement final\n",
    "final_df = processed_df.select(\n",
    "    \"userId\", \n",
    "    \"movieId\",\n",
    "    \"rating\",\n",
    "    \"normalized_rating\",\n",
    "    \"confidence\",\n",
    "    \"user_mean\",\n",
    "    \"user_stddev\",\n",
    "    \"movie_count\",\n",
    "    \"title\",      # du fichier movies.csv\n",
    "    \"genres\",     # du fichier movies.csv\n",
    "    \"timestamp\"   # garder le timestamp pour pouvoir faire des splits temporels\n",
    ")\n",
    "\n",
    "# Enregistrement des donn√©es pond√©r√©es dans le r√©pertoire HDFS\n",
    "print(f\"üíæ Enregistrement du fichier CSV pond√©r√© dans {output_path}...\")\n",
    "\n",
    "# V√©rifier si le r√©pertoire existe et le supprimer s'il existe d√©j√†\n",
    "try:\n",
    "    spark._jvm.org.apache.hadoop.fs.FileSystem.get(spark._jsc.hadoopConfiguration()).delete(\n",
    "        spark._jvm.org.apache.hadoop.fs.Path(output_path), True)\n",
    "except:\n",
    "    pass  # Le chemin n'existe pas, on continue\n",
    "\n",
    "# Enregistrer en CSV\n",
    "final_df.write.csv(output_path, header=True, mode=\"overwrite\")\n",
    "\n",
    "print(\"‚úÖ Pr√©traitement termin√©! Fichier pond√©r√© pr√™t √† √™tre utilis√©.\")\n",
    "\n",
    "# ====================== AFFICHAGE D'UN APER√áU DES DONN√âES PONDER√âES ======================\n",
    "print(\"\\nüìä Aper√ßu des donn√©es pond√©r√©es:\")\n",
    "final_df.select(\"userId\", \"movieId\", \"title\", \"rating\", \"normalized_rating\", \"confidence\").show(5)\n",
    "\n",
    "# ====================== STATISTIQUES SUPPL√âMENTAIRES ======================\n",
    "print(\"\\nüìà Statistiques suppl√©mentaires sur les donn√©es pond√©r√©es :\")\n",
    "final_df.select(\n",
    "    F.avg(\"confidence\").alias(\"avg_confidence\"),\n",
    "    F.countDistinct(\"userId\").alias(\"unique_users\"),\n",
    "    F.countDistinct(\"movieId\").alias(\"unique_movies\"),\n",
    "    F.avg(\"normalized_rating\").alias(\"avg_normalized_rating\")\n",
    ").show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
